{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJ-2a8LRro5"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6cApW345ukg"
      },
      "source": [
        "## MSDS458 Research Assignment 3 - Part 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hblbilyx5ukg"
      },
      "source": [
        "## Analyze AG_NEWS_SUBSET Data <br>\n",
        "\n",
        "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.<br>\n",
        "\n",
        "For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html<br>\n",
        "\n",
        "\n",
        "The AG's news topic classification dataset is constructed by choosing 4 largest classes (**World**, **Sports**, **Business**, and **Sci/Tech**) from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.<br>\n",
        "\n",
        "Homepage: https://arxiv.org/abs/1509.01626<br>\n",
        "\n",
        "Source code: tfds.text.AGNewsSubset\n",
        "\n",
        "Versions:\n",
        "\n",
        "1.0.0 (default): No release notes.\n",
        "Download size: 11.24 MiB\n",
        "\n",
        "Dataset size: 35.79 MiB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95DGbFzR5uki"
      },
      "source": [
        "## References\n",
        "1. Deep Learning with Python, Francois Chollet (https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/)\n",
        " * Chapter 10: Deep learning for time series\n",
        " * Chapter 11: Deep learning for text\n",
        "2. Deep Learning A Visual Approach, Andrew Glassner (https://learning.oreilly.com/library/view/deep-learning/9781098129019/)\n",
        " * Chapter 19: Recurrent Neural Networks\n",
        " * Chapter 20: Attention and Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8kwmgNRro7"
      },
      "source": [
        "## Processing words as a sequence: The sequence model approach\n",
        "\n",
        "To implement a sequence model, you’d start by representing your input samples as sequences of integer indices (one integer standing for one word). Then, you’d map each integer to a vector to obtain vector sequences. Finally, you’d feed these sequences of vectors into a stack of layers that could cross-correlate features from adjacent vectors, such as a 1D convnet, a RNN, or a Transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AQ7tuV5ukj"
      },
      "source": [
        "For some time around 2016–2017, bidirectional RNNs (in particular, `bidirectional LSTMs`) were considered to be the state of the art for sequence modeling. However, nowadays sequence modeling is almost universally done with `Transformers`.\n",
        "\n",
        "F. Chollet: \"One-dimensional convnets were never very popular in NLP, even though, a residual stack of depthwise-separable 1D convolutions can often achieve comparable performance to a bidirectional LSTM, at a greatly reduced computational cost.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydgzc1l15ukl"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9d9VZa_T5ukm"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNt8VbLK5ukp"
      },
      "source": [
        "## Verify TensorFlow version and Keras version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kujC9adr5ukq",
        "outputId": "f2ca2c84-762a-4670-f11a-d9d898c568c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This notebook requires TensorFlow 2.0 or above\n",
            "TensorFlow version:  2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHdPTZRp5ukr",
        "outputId": "62ae2a1a-8460-47d3-cad3-8caa1d77f1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version:  2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Keras version: \", keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpuz4g-xzFww"
      },
      "source": [
        "## Stopword Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JN7jFTYxzFww"
      },
      "outputs": [],
      "source": [
        "def custom_stopwords(input_text):\n",
        "    lowercase = tf.strings.lower(input_text)\n",
        "    stripped_punct = tf.strings.regex_replace(lowercase\n",
        "                                  ,'[%s]' % re.escape(string.punctuation)\n",
        "                                  ,'')\n",
        "    return tf.strings.regex_replace(stripped_punct, r'\\b(' + r'|'.join(STOPWORDS) + r')\\b\\s*',\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Gn6wYG5uks"
      },
      "source": [
        "## Mount Google Drive to Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8jHzLMMB5ukt"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvqFLia1Rro9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsypDzDARro-",
        "outputId": "7cf2c695-8cf2-4e3f-8030-f3a43ef925dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W0508 04:37:53.401716 133778626629632 download_and_prepare.py:46] ***`tfds build` should be used instead of `download_and_prepare`.***\n",
            "INFO[build.py]: Loading dataset ag_news_subset from imports: tensorflow_datasets.datasets.ag_news_subset.ag_news_subset_dataset_builder\n",
            "2024-05-08 04:37:54.295759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-08 04:37:54.295866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-08 04:37:54.299074: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-08 04:37:56.308401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO[utils.py]: NumExpr defaulting to 2 threads.\n",
            "2024-05-08 04:37:58.661949: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "INFO[dataset_info.py]: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "INFO[dataset_info.py]: Load dataset info from /tmp/tmp7_roo5jbtfds\n",
            "INFO[dataset_info.py]: For 'ag_news_subset/1.0.0': fields info.[description, splits, supervised_keys, module_name] differ on disk and in the code. Keeping the one from code.\n",
            "INFO[build.py]: download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "INFO[dataset_builder.py]: Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset 11.24 MiB (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "                                       \n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[AINFO[download_manager.py]: Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.31958188bffb4216bbaf7e88b433c746...\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:   0% 0/11 [00:15<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:   9% 1/11 [00:15<02:33, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  18% 2/11 [00:15<02:18, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  27% 3/11 [00:15<02:02, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  36% 4/11 [00:15<01:47, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  45% 5/11 [00:15<01:32, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  55% 6/11 [00:15<01:16, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  64% 7/11 [00:15<01:01, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  73% 8/11 [00:15<00:46, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  82% 9/11 [00:15<00:30, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  91% 10/11 [00:15<00:15, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...: 100% 11/11 [00:15<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:15<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:15<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/4 [00:16<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 15.77s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00, 15.34s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 4/4 [00:16<00:00,  4.09s/ file]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00,  1.49s/ MiB]\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 16.35s/ url]\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating train examples...:   2% 2404/120000 [00:01<00:49, 2395.99 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 7284/120000 [00:02<00:29, 3854.81 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 11627/120000 [00:03<00:26, 4077.27 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 15917/120000 [00:04<00:25, 4160.93 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 20225/120000 [00:05<00:23, 4213.61 examples/s]\u001b[A\n",
            "Generating train examples...:  21% 25053/120000 [00:06<00:21, 4422.29 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 30185/120000 [00:07<00:19, 4654.20 examples/s]\u001b[A\n",
            "Generating train examples...:  33% 39462/120000 [00:08<00:13, 6125.41 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 47618/120000 [00:09<00:10, 6759.84 examples/s]\u001b[A\n",
            "Generating train examples...:  45% 54379/120000 [00:10<00:10, 6396.09 examples/s]\u001b[A\n",
            "Generating train examples...:  53% 63531/120000 [00:11<00:07, 7207.39 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 72756/120000 [00:12<00:06, 7804.61 examples/s]\u001b[A\n",
            "Generating train examples...:  68% 81777/120000 [00:13<00:04, 8165.86 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 91358/120000 [00:14<00:03, 8587.60 examples/s]\u001b[A\n",
            "Generating train examples...:  84% 100970/120000 [00:15<00:02, 8893.31 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 110145/120000 [00:16<00:01, 8977.24 examples/s]\u001b[A\n",
            "Generating train examples...:  99% 119144/120000 [00:17<00:00, 8419.81 examples/s]\u001b[A\n",
            "                                                                                  \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:   0% 1/120000 [00:00<9:42:09,  3.44 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:  14% 16542/120000 [00:00<00:01, 54454.14 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:  32% 37801/120000 [00:00<00:00, 105023.68 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:  47% 56684/120000 [00:00<00:00, 131300.15 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:  64% 76593/120000 [00:00<00:00, 152266.74 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:  82% 97823/120000 [00:00<00:00, 170660.02 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*...:  99% 118254/120000 [00:00<00:00, 180899.55 examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-train.tfrecord*. Number of examples: 120000 (shards: [120000])\n",
            "Generating splits...:  50% 1/2 [00:18<00:18, 18.51s/ splits]\n",
            "Generating test examples...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating test examples...:  70% 5316/7600 [00:01<00:00, 5315.36 examples/s]\u001b[A\n",
            "                                                                             \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-test.tfrecord*...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incomplete1SS95G/ag_news_subset-test.tfrecord*. Number of examples: 7600 (shards: [7600])\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "INFO[build.py]: Dataset generation complete...\n",
            "\n",
            "tfds.core.DatasetInfo(\n",
            "    name='ag_news_subset',\n",
            "    full_name='ag_news_subset/1.0.0',\n",
            "    description=\"\"\"\n",
            "    AG is a collection of more than 1 million news articles. News articles have been\n",
            "    gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of\n",
            "    activity. ComeToMyHead is an academic news search engine which has been running\n",
            "    since July, 2004. The dataset is provided by the academic comunity for research\n",
            "    purposes in data mining (clustering, classification, etc), information retrieval\n",
            "    (ranking, search, etc), xml, data compression, data streaming, and any other\n",
            "    non-commercial activity. For more information, please refer to the link\n",
            "    http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by Xiang Zhang\n",
            "    (xiang.zhang@nyu.edu) from the dataset above. It is used as a text\n",
            "    classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann\n",
            "    LeCun. Character-level Convolutional Networks for Text Classification. Advances\n",
            "    in Neural Information Processing Systems 28 (NIPS 2015).\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by choosing 4 largest\n",
            "    classes from the original corpus. Each class contains 30,000 training samples\n",
            "    and 1,900 testing samples. The total number of training samples is 120,000 and\n",
            "    testing 7,600.\n",
            "    \"\"\",\n",
            "    homepage='https://arxiv.org/abs/1509.01626',\n",
            "    data_dir=PosixGPath('/tmp/tmp7_roo5jbtfds'),\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.24 MiB,\n",
            "    dataset_size=35.79 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'description': Text(shape=(), dtype=string),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=4),\n",
            "        'title': Text(shape=(), dtype=string),\n",
            "    }),\n",
            "    supervised_keys=('description', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=7600, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=120000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@misc{zhang2015characterlevel,\n",
            "        title={Character-level Convolutional Networks for Text Classification},\n",
            "        author={Xiang Zhang and Junbo Zhao and Yann LeCun},\n",
            "        year={2015},\n",
            "        eprint={1509.01626},\n",
            "        archivePrefix={arXiv},\n",
            "        primaryClass={cs.LG}\n",
            "    }\"\"\",\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# register  ag_news_subset so that tfds.load doesn't generate a checksum (mismatch) error\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "\n",
        "dataset,info=\\\n",
        "tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test'],batch_size = 32\n",
        "          , as_supervised=True)\n",
        "\n",
        "train_ds, val_ds, test_ds = dataset\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7Q6zlFRro_"
      },
      "source": [
        "## Preparing Integer Sequence Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9nuyg01zFwx",
        "outputId": "1d0128c9-25ad-4153-d07b-1e84e1979e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AfTnCGIERrpA"
      },
      "outputs": [],
      "source": [
        "max_length = 150\n",
        "max_tokens = 1000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        "    standardize=custom_stopwords\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBL0CkaB5ukv"
      },
      "source": [
        "## Bi-directional RNN\n",
        "\n",
        "When translating in real-time, it would help to have access to worlds towards the end of a sentence, say, as well as earlier words in the sentence. One way to use the later words in the sentence is to feed the words into our RNN backward. So if we create two independent RNNs, we can feed one the words in their forward, or natural order, and the second gets their words in the revser order. This is the idea behind `Bi-directional RNNS`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuP7exeZ5ukw"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/BidirectionalRNN.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCNo3kUl5ukw"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/Bidirectional2RNN.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN2wjSjdRrpB"
      },
      "source": [
        "## Sequence Model Built on One-Hot Encoded Vector Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq6dB-zWRrpB",
        "outputId": "e7766ccc-8818-477e-a3f6-c4a35c488203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 1000)        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                264448    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264708 (1.01 MB)\n",
            "Trainable params: 264708 (1.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64NWZQc5ukx"
      },
      "source": [
        "## One input is a sequence of integers.\n",
        "\n",
        "1. In order to keep a manageable input size, we’ll truncate the inputs after the first 150 words. This is a reasonable choice, since the average review length is 233 words, and only 5% of reviews are longer than 150 words.\n",
        "\n",
        "2. Encode the integers into binary 1,000-dimensional vectors.\n",
        "\n",
        "3. Add a bidirectional LSTM.\n",
        "\n",
        "4. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognTeJM6RrpC"
      },
      "source": [
        "## Training Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kCbHrrsRrpC",
        "outputId": "796f8dbd-86dd-438e-a06d-313a3d13c085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 54s 13ms/step - loss: 0.5804 - accuracy: 0.7951 - val_loss: 0.4224 - val_accuracy: 0.8522\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.4374 - accuracy: 0.8498 - val_loss: 0.4058 - val_accuracy: 0.8575\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.4233 - accuracy: 0.8546 - val_loss: 0.3985 - val_accuracy: 0.8570\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.4126 - accuracy: 0.8575 - val_loss: 0.3934 - val_accuracy: 0.8583\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 46s 13ms/step - loss: 0.4056 - accuracy: 0.8592 - val_loss: 0.3921 - val_accuracy: 0.8598\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3991 - accuracy: 0.8615 - val_loss: 0.3930 - val_accuracy: 0.8570\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3934 - accuracy: 0.8633 - val_loss: 0.3896 - val_accuracy: 0.8613\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 48s 13ms/step - loss: 0.3889 - accuracy: 0.8656 - val_loss: 0.3921 - val_accuracy: 0.8605\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 46s 13ms/step - loss: 0.3829 - accuracy: 0.8666 - val_loss: 0.3877 - val_accuracy: 0.8620\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 46s 13ms/step - loss: 0.3794 - accuracy: 0.8680 - val_loss: 0.3924 - val_accuracy: 0.8602\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3762 - accuracy: 0.8695 - val_loss: 0.3921 - val_accuracy: 0.8600\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3728 - accuracy: 0.8711 - val_loss: 0.3925 - val_accuracy: 0.8600\n",
            "238/238 [==============================] - 3s 8ms/step - loss: 0.3946 - accuracy: 0.8605\n",
            "Test acc: 0.861\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTprEi3bRrpD"
      },
      "source": [
        "## Understanding word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmHdhUnM5ukz"
      },
      "source": [
        "When you encode something via `one-hot encoding`, you’re making a feature-engineering decision. You’re injecting into your model a fundamental assumption about the structure of your feature space. That assumption is that the different tokens you’re encoding are all independent from each other: indeed, one-hot vectors are all orthogonal to one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "webaWkZJ5ukz"
      },
      "source": [
        "However, in a reasonable word vector space, you would expect synonyms to be embedded into similar word vectors, and in general, you would expect the geometric distance  between any two word vectors to relate to the “semantic distance” between the associated words.\n",
        "\n",
        "Words that mean different things should lie far away from each other, whereas related words should be closer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-W1sFgg5ukz"
      },
      "source": [
        "`Word embeddings` are vector representations of words that achieve exactly this: they map human language into a structured geometric space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egzHasW5ukz"
      },
      "source": [
        "Whereas the vectors obtained through `one-hot encoding` are *binary*, *sparse*, and *very high-dimensional* (the same dimensionality as the number of words in the vocabulary), `word embeddings` are *low-dimensional floating-point vectors* (that is, `dense vectors`, as opposed to `sparse vectors`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHU4tS3b5uk0"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/EmbeddingsSparse.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im1j5PRE5uk0"
      },
      "source": [
        "## Two ways to obtain word embeddings\n",
        "\n",
        "1. `Learn word embeddings jointly with the main task you care about` (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
        "2. Load into your model word embeddings that were precomputed using a different machine learning task than the one you’re trying to solve. These are called `pretrained word embeddings`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNyH_fhRrpD"
      },
      "source": [
        "## Learning Word Embeddings With The Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsYLfdJY5uk0"
      },
      "source": [
        "What makes a good word-embedding space depends heavily on your task: the perfect word-embedding space for an English-language movie-review sentiment-analysis model may look different from the perfect embedding space for an English-language legal-document classification model, because the importance of certain semantic relationships varies from task to task.\n",
        "\n",
        "It’s thus reasonable to learn a new embedding space with every new task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j69C96c65uk1"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>tf.keras.layers.Embedding</b><br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrVeqKcsRrpE"
      },
      "source": [
        "## Instantiating An Embedding Layer\n",
        "\n",
        "The Embedding layer takes at least two arguments: the number of possible tokens and the dimensionality of the embeddings (here, 256)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WLTjxbMnRrpE"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWx26f9C5uk2"
      },
      "source": [
        "The Embedding layer is best understood as a dictionary that maps integer indices (which stand for specific words) to dense vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mox7FQp5uk2"
      },
      "source": [
        "The Embedding layer takes as input a rank-2 tensor of integers, of shape `(batch_size, sequence_length)`, where each entry is a sequence of integers. The layer then returns a 3D floating-point tensor of shape `(batch_size, sequence_length, embedding_ dimensionality)`.Again, embedding_ dimensionality is 256 above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSfWWNO6RrpE"
      },
      "source": [
        "## Model Leveraging Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLuGKCM35uk2"
      },
      "source": [
        "One input is a sequence of integers.\n",
        "1. Encode the integers into binary 20,000-dimensional vectors.\n",
        "2. Add a bidirectional LSTM.\n",
        "3. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6JFON-CRrpF",
        "outputId": "4802f297-b342-4614-ea04-799d9f4950dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330244 (1.26 MB)\n",
            "Trainable params: 330244 (1.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 60s 16ms/step - loss: 0.5212 - accuracy: 0.8155 - val_loss: 0.4141 - val_accuracy: 0.8545\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.4296 - accuracy: 0.8517 - val_loss: 0.3951 - val_accuracy: 0.8592\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 48s 14ms/step - loss: 0.4057 - accuracy: 0.8589 - val_loss: 0.3825 - val_accuracy: 0.8610\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3947 - accuracy: 0.8618 - val_loss: 0.3804 - val_accuracy: 0.8623\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3859 - accuracy: 0.8659 - val_loss: 0.3770 - val_accuracy: 0.8662\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 48s 13ms/step - loss: 0.3770 - accuracy: 0.8684 - val_loss: 0.3778 - val_accuracy: 0.8630\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3726 - accuracy: 0.8711 - val_loss: 0.3755 - val_accuracy: 0.8662\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3646 - accuracy: 0.8731 - val_loss: 0.3762 - val_accuracy: 0.8675\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3577 - accuracy: 0.8758 - val_loss: 0.3827 - val_accuracy: 0.8622\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3510 - accuracy: 0.8792 - val_loss: 0.3865 - val_accuracy: 0.8645\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 48s 13ms/step - loss: 0.3447 - accuracy: 0.8806 - val_loss: 0.3902 - val_accuracy: 0.8648\n",
            "238/238 [==============================] - 3s 6ms/step - loss: 0.3909 - accuracy: 0.8649\n",
            "Test acc: 0.865\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHF_wA3x5uk3"
      },
      "source": [
        "It trains much faster than the one-hot model (since the LSTM only has to process 256-dimensional vectors instead of 1,000-dimensional), and its test accuracy is comparable (86%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0gOTdNnRrpF"
      },
      "source": [
        "## Understanding Padding and Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOudeXoa5uk4"
      },
      "source": [
        "One thing that’s slightly hurting model performance here is that our input sequences are full of zeros. This comes from our use of the `output_sequence_length=max_ length` option in TextVectorization (with `max_length equal` to 150): sentences longer than 150 tokens are truncated to a length of 150 tokens, and sentences shorter than 150 tokens are padded with zeros at the end so that they can be concatenated together with other sequences to form contiguous batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM95tdc65uk4"
      },
      "source": [
        "The RNN that looks at the tokens in their natural order will spend its last iterations seeing only vectors that encode padding—possibly for several hundreds of iterations if the original sentence was short. The information stored in the internal state of the RNN will gradually fade out as it gets exposed to these meaningless inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U93_Szgn5uk4"
      },
      "source": [
        "We need some way to tell the RNN that it should skip these iterations. There’s an API for that: `masking`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1SxQSW85uk4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>tf.keras.layers.Masking</b><br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGe0pvoxRrpF"
      },
      "source": [
        "## Model Leveraging Embedding Layer With Masking Enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6YKNrDRrpF",
        "outputId": "ba7c1cc8-9a8c-4d8b-abd0-db132bba08c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330244 (1.26 MB)\n",
            "Trainable params: 330244 (1.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 67s 16ms/step - loss: 0.4864 - accuracy: 0.8279 - val_loss: 0.4067 - val_accuracy: 0.8558\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.4158 - accuracy: 0.8530 - val_loss: 0.3921 - val_accuracy: 0.8615\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 46s 13ms/step - loss: 0.3978 - accuracy: 0.8583 - val_loss: 0.3871 - val_accuracy: 0.8632\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3853 - accuracy: 0.8638 - val_loss: 0.3821 - val_accuracy: 0.8658\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3740 - accuracy: 0.8677 - val_loss: 0.3802 - val_accuracy: 0.8658\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3647 - accuracy: 0.8711 - val_loss: 0.3805 - val_accuracy: 0.8680\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 48s 13ms/step - loss: 0.3569 - accuracy: 0.8746 - val_loss: 0.3807 - val_accuracy: 0.8673\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3488 - accuracy: 0.8775 - val_loss: 0.3868 - val_accuracy: 0.8687\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3430 - accuracy: 0.8802 - val_loss: 0.3868 - val_accuracy: 0.8675\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 48s 13ms/step - loss: 0.3348 - accuracy: 0.8828 - val_loss: 0.3863 - val_accuracy: 0.8670\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 47s 13ms/step - loss: 0.3274 - accuracy: 0.8854 - val_loss: 0.3900 - val_accuracy: 0.8682\n",
            "238/238 [==============================] - 6s 5ms/step - loss: 0.3943 - accuracy: 0.8630\n",
            "Test acc: 0.863\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDRunHYSRrpG"
      },
      "source": [
        "## Using Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivO55Vo15uk6"
      },
      "source": [
        "The rationale behind using `pretrained word embedding`s in natural language processing is much the same as for using pretrained convnets in image classification: *you don’t have enough data available to learn truly powerful features on your own*, but you expect that the features you need are fairly generic—that is, common visual features or semantic features. In this case, it makes sense to reuse features learned on a different problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XllLQfXb5uk6"
      },
      "source": [
        "The idea of a dense, low-dimensional embedding space for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s, but it only started to take off in research and industry applications after the release of one of the most famous and successful word-embedding schemes: the `Word2Vec` algorithm (https://code.google.com/archive/p/word2vec), developed by Tomas Mikolov at Google in 2013. `Word2Vec` dimensions capture specific semantic properties, such as gender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riqJwrpr5uk6"
      },
      "source": [
        "There are various precomputed databases of word embeddings that you can download and use in a Keras Embedding layer. `Word2vec` is one of them. Another popular one is called `Global Vectors for Word Representatio`n (GloVe, https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This embedding technique is based on factorizing a matrix of word co-occurrence statistics. Its developers have made available precomputed embeddings for millions of English tokens, obtained from Wikipedia data and Common Crawl data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNrxDE65uk6"
      },
      "source": [
        "First, let’s download the GloVe word embeddings precomputed on the 2014 English Wikipedia dataset. It’s an 822 MB zip file containing 100-dimensional embedding vectors for 400,000 words (or non-word tokens)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6O5iXN5uk7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>GloVe: Global Vectors for Word Representation</b><br>\n",
        "https://nlp.stanford.edu/projects/glove/</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EjBZq6cRrpG",
        "outputId": "9b2b436e-a397-43de-bb81-2d5a6aed0494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-08 04:20:46--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-05-08 04:20:47--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-05-08 04:20:47--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-05-08 04:23:27 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ifl-sJRrpH"
      },
      "source": [
        "## Parsing The GloVe Word-Embeddings File\n",
        "\n",
        "First line of `glove.6B.100d.txt`:\n",
        "\n",
        "`the -0.038194 -0.24487 0.72812 ...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPo9aWdbRrpH",
        "outputId": "a7031350-18e9-4ed5-baef-73ea5cd1f78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \") # np.dtype('f') returns dtype('float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evKxdRndRrpH"
      },
      "source": [
        "## Preparing The GloVe Word-Embeddings Matrix\n",
        "\n",
        "Next, let’s build an embedding matrix that you can load into an Embedding layer. It must be a matrix of shape `(max_words, embedding_dim)`, where each entry *i* contains the `embedding_dim`-dimensional vector for the word of index *i* in the reference word index (built during tokenization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jSCD2_KcRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "# Retrieve the vocabulary indexed by our previous TextVectorization layer.\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "# Use it to create a mapping from words to their index in the vocabulary.\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "# Prepare a matrix that we’ll fill with the GloVe vectors.\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "\n",
        "# Fill entry i in the matrix with the word vector for index i.\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:  # Words not found in the embedding index will be all zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZE2xRs4QRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUsE9u-g5uk9"
      },
      "source": [
        "We’re now ready to train a new model—identical to our previous model, but leveraging the `100-dimensional` pretrained GloVe embeddings instead of `256-dimensional` learned embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aXYeW8o5uk9"
      },
      "source": [
        "## One possible alternative to GloVE: ELMo (Embedding from Language Models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOckichs5uk9"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/ELMoArchitecture.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeEWdhm_5uk9"
      },
      "source": [
        "### \"Although the word is written in the identical way in each sentence, ELMo is able to identify the correct embedding based on the word’s context.\"\n",
        "\n",
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/ELMoComparison.png?raw=1\">\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=cPMCaxrZwp7t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOA_ss3iRrpJ"
      },
      "source": [
        "## Model Leveraging Pretrained (GloVe) Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI8Tj4g1RrpJ",
        "outputId": "316e1d7d-76d1-45fe-8572-edccc8ab2793",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         100000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                34048     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134308 (524.64 KB)\n",
            "Trainable params: 34308 (134.02 KB)\n",
            "Non-trainable params: 100000 (390.62 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 902s 249ms/step - loss: 0.4827 - accuracy: 0.8274 - val_loss: 0.4116 - val_accuracy: 0.8530\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 890s 250ms/step - loss: 0.4247 - accuracy: 0.8471 - val_loss: 0.3976 - val_accuracy: 0.8562\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 875s 245ms/step - loss: 0.4060 - accuracy: 0.8541 - val_loss: 0.3868 - val_accuracy: 0.8597\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 878s 247ms/step - loss: 0.3960 - accuracy: 0.8579 - val_loss: 0.3830 - val_accuracy: 0.8610\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 895s 251ms/step - loss: 0.3853 - accuracy: 0.8608 - val_loss: 0.3754 - val_accuracy: 0.8627\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 917s 257ms/step - loss: 0.3785 - accuracy: 0.8637 - val_loss: 0.3746 - val_accuracy: 0.8635\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 880s 247ms/step - loss: 0.3722 - accuracy: 0.8662 - val_loss: 0.3771 - val_accuracy: 0.8628\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 862s 242ms/step - loss: 0.3677 - accuracy: 0.8684 - val_loss: 0.3769 - val_accuracy: 0.8630\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 889s 250ms/step - loss: 0.3618 - accuracy: 0.8706 - val_loss: 0.3717 - val_accuracy: 0.8642\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 899s 252ms/step - loss: 0.3578 - accuracy: 0.8715 - val_loss: 0.3720 - val_accuracy: 0.8652\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 887s 249ms/step - loss: 0.3526 - accuracy: 0.8744 - val_loss: 0.3726 - val_accuracy: 0.8665\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 896s 252ms/step - loss: 0.3494 - accuracy: 0.8755 - val_loss: 0.3744 - val_accuracy: 0.8635\n",
            "Epoch 13/200\n",
            "3563/3563 [==============================] - 889s 250ms/step - loss: 0.3453 - accuracy: 0.8763 - val_loss: 0.3731 - val_accuracy: 0.8618\n",
            "Epoch 14/200\n",
            "3563/3563 [==============================] - 890s 250ms/step - loss: 0.3413 - accuracy: 0.8777 - val_loss: 0.3780 - val_accuracy: 0.8618\n",
            "238/238 [==============================] - 26s 78ms/step - loss: 0.3845 - accuracy: 0.8616\n",
            "Test acc: 0.862\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5fqFXCOO5uk-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "MSDS458_Assignment_03_part02_SequenceModels_20220421_DEV_v4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}