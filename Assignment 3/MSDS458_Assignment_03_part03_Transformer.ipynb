{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimlfacnwu/MSDS_458_Fall2022/blob/MSDS_458_Spring2022/Assignment%203/MSDS458_Assignment_03_part03_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYLKJ1LZmJZT"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUwiDnKQmJZb"
      },
      "source": [
        "### Analyze AG_NEWS_SUBSET Data <br>\n",
        "\n",
        "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.<br>\n",
        "\n",
        "For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html<br>\n",
        "\n",
        "\n",
        "The AG's news topic classification dataset is constructed by choosing 4 largest classes (**World**, **Sports**, **Business**, and **Sci/Tech**) from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.<br>\n",
        "\n",
        "Homepage: https://arxiv.org/abs/1509.01626<br>\n",
        "\n",
        "Source code: tfds.text.AGNewsSubset\n",
        "\n",
        "Versions:\n",
        "\n",
        "1.0.0 (default): No release notes.\n",
        "Download size: 11.24 MiB\n",
        "\n",
        "Dataset size: 35.79 MiB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyg3hsjLmJZd"
      },
      "source": [
        "## References\n",
        "1. Deep Learning with Python, Francois Chollet (https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/)\n",
        " * Chapter 10: Deep learning for time series\n",
        " * Chapter 11: Deep learning for text\n",
        "2. Deep Learning A Visual Approach, Andrew Glassner (https://learning.oreilly.com/library/view/deep-learning/9781098129019/)\n",
        " * Chapter 19: Recurrent Neural Networks\n",
        " * Chapter 20: Attention and Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9xKmjEmJZe"
      },
      "source": [
        "## The Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfccUEzfmJZe"
      },
      "source": [
        "## Understanding Self-Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2bD03q0mJZf"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/SelfAttention.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpM0ncXJmJZf"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/DogAte.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf-7KKzWmJZg"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/InputOutput.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2-0mq4EmJZh"
      },
      "source": [
        "## Generalized Self-Attention: The Query-Key-Value Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dpn42iOmJZi"
      },
      "source": [
        "#### Retrieving images from a database: the “query” is compared to a set of “keys,” and the match scores are used to rank “values” (images).\n",
        "\n",
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/DogsBeach.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZMx9VAcmJZj"
      },
      "source": [
        "## Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AteVsVIpmJZj"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/MultiHead.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfJGIx4EmJZj"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gnF865oHmJZk"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "from keras import layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SO5DzBCmJZm"
      },
      "source": [
        "## Verify TensorFlow Version and Keras Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMmbJHDImJZm",
        "outputId": "bde509f6-105b-497b-a131-d1af6fedad9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This notebook requires TensorFlow 2.0 or above\n",
            "TensorFlow version:  2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1HcGXWoDRDP",
        "outputId": "9aa5062a-6d4d-49a2-f69f-7465684dfaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version:  2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Keras version: \", keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwu_R0PxDRDQ"
      },
      "source": [
        "## Mount Google Drive to Colab Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8-hkaU_TDRDQ"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffs4EljMmJZm"
      },
      "source": [
        "## The Transformer Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VSZ6gB_mJZn"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl0z_01vmJZn",
        "outputId": "efb353e8-e7a2-4bb0-f9a8-5971d89ba0ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W0508 08:31:19.702051 137317054956672 download_and_prepare.py:46] ***`tfds build` should be used instead of `download_and_prepare`.***\n",
            "INFO[build.py]: Loading dataset ag_news_subset from imports: tensorflow_datasets.datasets.ag_news_subset.ag_news_subset_dataset_builder\n",
            "2024-05-08 08:31:20.024277: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-08 08:31:20.024333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-08 08:31:20.025549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-08 08:31:21.717071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO[utils.py]: NumExpr defaulting to 2 threads.\n",
            "2024-05-08 08:31:23.378452: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "INFO[dataset_info.py]: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "INFO[dataset_info.py]: Load dataset info from /tmp/tmpnacig8astfds\n",
            "INFO[dataset_info.py]: For 'ag_news_subset/1.0.0': fields info.[description, splits, supervised_keys, module_name] differ on disk and in the code. Keeping the one from code.\n",
            "INFO[build.py]: download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "INFO[dataset_builder.py]: Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset 11.24 MiB (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "                                       \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[AINFO[download_manager.py]: Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.bae5ae7393974d4abe06f77376c8cc47...\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:20<?, ? url/s]\n",
            "Dl Size...:   0% 0/11 [00:20<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:20<?, ? url/s]\n",
            "Dl Size...:   9% 1/11 [00:20<03:27, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:20<?, ? url/s]\n",
            "Dl Size...:  18% 2/11 [00:20<03:06, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:20<?, ? url/s]\n",
            "Dl Size...:  27% 3/11 [00:20<02:46, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  36% 4/11 [00:21<02:25, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  45% 5/11 [00:21<02:04, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  55% 6/11 [00:21<01:43, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  64% 7/11 [00:21<01:23, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  73% 8/11 [00:21<01:02, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  82% 9/11 [00:21<00:41, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...:  91% 10/11 [00:21<00:20, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:21<?, ? url/s]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/4 [00:21<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.44s/ url]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00, 20.76s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 4/4 [00:21<00:00,  5.42s/ file]\n",
            "Dl Size...: 100% 11/11 [00:21<00:00,  1.97s/ MiB]\n",
            "Dl Completed...: 100% 1/1 [00:21<00:00, 21.70s/ url]\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating train examples...:   5% 6257/120000 [00:01<00:18, 6256.47 examples/s]\u001b[A\n",
            "Generating train examples...:  11% 13180/120000 [00:02<00:16, 6648.34 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 19829/120000 [00:03<00:15, 6625.15 examples/s]\u001b[A\n",
            "Generating train examples...:  22% 26455/120000 [00:04<00:14, 6511.00 examples/s]\u001b[A\n",
            "Generating train examples...:  32% 37963/120000 [00:05<00:09, 8290.42 examples/s]\u001b[A\n",
            "Generating train examples...:  42% 49898/120000 [00:06<00:07, 9519.19 examples/s]\u001b[A\n",
            "Generating train examples...:  52% 61828/120000 [00:07<00:05, 10302.75 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 73573/120000 [00:08<00:04, 10760.04 examples/s]\u001b[A\n",
            "Generating train examples...:  71% 85317/120000 [00:09<00:03, 11066.75 examples/s]\u001b[A\n",
            "Generating train examples...:  81% 97098/120000 [00:10<00:02, 11286.75 examples/s]\u001b[A\n",
            "Generating train examples...:  90% 108508/120000 [00:11<00:01, 11324.33 examples/s]\u001b[A\n",
            "                                                                                   \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-train.tfrecord*...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-train.tfrecord*...:   9% 10906/120000 [00:00<00:01, 109052.82 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-train.tfrecord*...:  52% 62087/120000 [00:00<00:00, 345948.03 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-train.tfrecord*...:  92% 110208/120000 [00:00<00:00, 407697.38 examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-train.tfrecord*. Number of examples: 120000 (shards: [120000])\n",
            "Generating splits...:  50% 1/2 [00:12<00:12, 12.37s/ splits]\n",
            "Generating test examples...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "                                                                \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-test.tfrecord*...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteCWPAXP/ag_news_subset-test.tfrecord*. Number of examples: 7600 (shards: [7600])\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "INFO[build.py]: Dataset generation complete...\n",
            "\n",
            "tfds.core.DatasetInfo(\n",
            "    name='ag_news_subset',\n",
            "    full_name='ag_news_subset/1.0.0',\n",
            "    description=\"\"\"\n",
            "    AG is a collection of more than 1 million news articles. News articles have been\n",
            "    gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of\n",
            "    activity. ComeToMyHead is an academic news search engine which has been running\n",
            "    since July, 2004. The dataset is provided by the academic comunity for research\n",
            "    purposes in data mining (clustering, classification, etc), information retrieval\n",
            "    (ranking, search, etc), xml, data compression, data streaming, and any other\n",
            "    non-commercial activity. For more information, please refer to the link\n",
            "    http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by Xiang Zhang\n",
            "    (xiang.zhang@nyu.edu) from the dataset above. It is used as a text\n",
            "    classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann\n",
            "    LeCun. Character-level Convolutional Networks for Text Classification. Advances\n",
            "    in Neural Information Processing Systems 28 (NIPS 2015).\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by choosing 4 largest\n",
            "    classes from the original corpus. Each class contains 30,000 training samples\n",
            "    and 1,900 testing samples. The total number of training samples is 120,000 and\n",
            "    testing 7,600.\n",
            "    \"\"\",\n",
            "    homepage='https://arxiv.org/abs/1509.01626',\n",
            "    data_dir=PosixGPath('/tmp/tmpnacig8astfds'),\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.24 MiB,\n",
            "    dataset_size=35.79 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'description': Text(shape=(), dtype=string),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=4),\n",
            "        'title': Text(shape=(), dtype=string),\n",
            "    }),\n",
            "    supervised_keys=('description', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=7600, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=120000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@misc{zhang2015characterlevel,\n",
            "        title={Character-level Convolutional Networks for Text Classification},\n",
            "        author={Xiang Zhang and Junbo Zhao and Yann LeCun},\n",
            "        year={2015},\n",
            "        eprint={1509.01626},\n",
            "        archivePrefix={arXiv},\n",
            "        primaryClass={cs.LG}\n",
            "    }\"\"\",\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# register  ag_news_subset so that tfds.load doesn't generate a checksum (mismatch) error\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "\n",
        "dataset, info = tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test'],batch_size = 32, as_supervised=True)\n",
        "train_ds, val_ds, test_ds = dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-3qpx9ZmJZo"
      },
      "source": [
        "## Preparing Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p2_CEJjimJZp"
      },
      "outputs": [],
      "source": [
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytPi4XCImJZp"
      },
      "source": [
        "## Vectorizing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l-DVBPWGmJZp"
      },
      "outputs": [],
      "source": [
        "max_length = 52\n",
        "max_tokens = 1000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPVABV8vmJZq"
      },
      "source": [
        "## Transformer Encoder Implemented As Subclassed `Layer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OscOAvHfmJZq"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtiaDM_nmJZq"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/TransformerEncoder.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQNlcHvpmJZr"
      },
      "source": [
        "## Using Transformer Encoder For Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNKHwoBAmJZr",
        "outputId": "7c19137a-a825-4e68-c187-12e4f452a978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         256000    \n",
            "                                                                 \n",
            " transformer_encoder (Trans  (None, None, 256)         543776    \n",
            " formerEncoder)                                                  \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 256)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 800804 (3.05 MB)\n",
            "Trainable params: 800804 (3.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 1000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjpJFn52mJZr"
      },
      "source": [
        "## Training and Evaluating Transformer Encoder Based Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJP3RBaBmJZr",
        "outputId": "7c78c72c-3ccd-45fd-caf7-699dc0ae3265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 46s 11ms/step - loss: 0.5171 - accuracy: 0.8148 - val_loss: 0.4022 - val_accuracy: 0.8575\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 33s 9ms/step - loss: 0.4167 - accuracy: 0.8498 - val_loss: 0.3837 - val_accuracy: 0.8623\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 33s 9ms/step - loss: 0.3971 - accuracy: 0.8570 - val_loss: 0.3785 - val_accuracy: 0.8642\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 34s 10ms/step - loss: 0.3860 - accuracy: 0.8608 - val_loss: 0.3693 - val_accuracy: 0.8662\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 32s 9ms/step - loss: 0.3774 - accuracy: 0.8640 - val_loss: 0.3747 - val_accuracy: 0.8623\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 33s 9ms/step - loss: 0.3697 - accuracy: 0.8670 - val_loss: 0.3764 - val_accuracy: 0.8628\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 32s 9ms/step - loss: 0.3630 - accuracy: 0.8689 - val_loss: 0.3683 - val_accuracy: 0.8645\n",
            "238/238 [==============================] - 3s 10ms/step - loss: 0.3883 - accuracy: 0.8597\n",
            "Test acc: 0.860\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\",save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "    ]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\n",
        "    \"transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49CU5NhjmJZs"
      },
      "source": [
        "## Using Positional Encoding to Re-Inject Order Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6thjuXg1mJZs"
      },
      "source": [
        "## Implementing Positional Embedding As Subclassed Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wZ5-2z1WmJZs"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwekVVu5mJZt"
      },
      "source": [
        "## Putting it all together: A text-classification Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "friLWNBzmJZt"
      },
      "source": [
        "## Combining Transformer Encoder with Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeVw84ygmJZt",
        "outputId": "745af1eb-073f-4047-cdc7-03a78cdc8659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " positional_embedding (Posi  (None, None, 256)         269312    \n",
            " tionalEmbedding)                                                \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tra  (None, None, 256)         543776    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 256)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 814116 (3.11 MB)\n",
            "Trainable params: 814116 (3.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 44s 12ms/step - loss: 0.5200 - accuracy: 0.8123 - val_loss: 0.3914 - val_accuracy: 0.8620\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 35s 10ms/step - loss: 0.4107 - accuracy: 0.8518 - val_loss: 0.3885 - val_accuracy: 0.8610\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 33s 9ms/step - loss: 0.3915 - accuracy: 0.8594 - val_loss: 0.3777 - val_accuracy: 0.8627\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 35s 10ms/step - loss: 0.3790 - accuracy: 0.8630 - val_loss: 0.3761 - val_accuracy: 0.8605\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 36s 10ms/step - loss: 0.3691 - accuracy: 0.8672 - val_loss: 0.3707 - val_accuracy: 0.8668\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 34s 9ms/step - loss: 0.3596 - accuracy: 0.8704 - val_loss: 0.3687 - val_accuracy: 0.8677\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 35s 10ms/step - loss: 0.3517 - accuracy: 0.8739 - val_loss: 0.3711 - val_accuracy: 0.8683\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 34s 10ms/step - loss: 0.3450 - accuracy: 0.8773 - val_loss: 0.3724 - val_accuracy: 0.8658\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 35s 10ms/step - loss: 0.3383 - accuracy: 0.8794 - val_loss: 0.3697 - val_accuracy: 0.8663\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 34s 10ms/step - loss: 0.3332 - accuracy: 0.8816 - val_loss: 0.3741 - val_accuracy: 0.8653\n",
            "238/238 [==============================] - 2s 6ms/step - loss: 0.3908 - accuracy: 0.8607\n",
            "Test acc: 0.861\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 1000\n",
        "sequence_length = 52\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\",save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\n",
        "    \"full_transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
        "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lyfC1axmJZu"
      },
      "source": [
        "## When To Use Sequence Models over Bag-of-Words Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh30ecbrmJZu"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/SequenceVBagWords.png?raw=1\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1lqhPc3ImJZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}