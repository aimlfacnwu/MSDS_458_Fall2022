{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50a4841b"
   },
   "source": [
    "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg8FIQdIARYk"
   },
   "source": [
    "## MSDS458 Research Assignment 02  Part 2 - TSNE\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>More Technical</b>: Throughout the notebook. This types of boxes provide more technical details and extra references about what you are seeing. They contain helpful tips, but you can safely skip them the first time you run through the code.\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f8O4UeqARdm"
   },
   "source": [
    "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d2uj-OtARkg"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>The CIFAR-10 dataset</b><br>\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR9iYlSlARul"
   },
   "source": [
    "## Import packages needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64824b68"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from packaging import version\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, Input, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRfc0ieNA8_r"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXjpyi0zCitX"
   },
   "source": [
    "## Verify TensorFlow Version and Keras Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_Ecxfw2CnZn",
    "outputId": "07640813-798a-4525-eb68-f286f2f207aa"
   },
   "outputs": [],
   "source": [
    "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTrbOP0tCno2",
    "outputId": "1c7e0935-9567-4f37-a58c-6fa2fa7a700d"
   },
   "outputs": [],
   "source": [
    "print(\"Keras version: \", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwpAGGeRCxKt"
   },
   "source": [
    "## Mount Google Drive to Colab Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFrd37D646zC",
    "outputId": "6417af2a-e910-4d7d-bf7c-28fae9a76689"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owlSNCrNDLv5"
   },
   "source": [
    "## Loading cifar10 Dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.<br>\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9ae9e86",
    "outputId": "facf76cc-fe45-4dae-fb0c-06b69a0f2404"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn396S7-FZy6"
   },
   "source": [
    "* Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test).\n",
    "* x_train, x_test: uint8 arrays of color image data with shapes (num_samples, 32, 32).\n",
    "* y_train, y_test: uint8 arrays of digit labels (integers in range 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEKJDXqEFjWo"
   },
   "source": [
    "## Preprocess Data For Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i87pbs3VGQfz"
   },
   "source": [
    "The labels are an array of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents:\n",
    "\n",
    "|Label  |Class_  |\n",
    "|-------|--------|\n",
    "|0|\tairplane     |\n",
    "|1|\tautomobile   |\n",
    "|2|\tbird         |\n",
    "|3|\tcat          |\n",
    "|4|\tdeer         |\n",
    "|5|\tdog          |\n",
    "|6|\tfrog         |\n",
    "|7|\thorse        |\n",
    "|8|\tship         |\n",
    "|9|\ttruck        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13b46d41"
   },
   "outputs": [],
   "source": [
    "class_names = ['airplane'\n",
    ",'automobile'\n",
    ",'bird'\n",
    ",'cat'\n",
    ",'deer'\n",
    ",'dog'\n",
    ",'frog' \n",
    ",'horse'\n",
    ",'ship'\n",
    ",'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbHmrqBSGpv4"
   },
   "source": [
    "## Create Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4f613d1d"
   },
   "outputs": [],
   "source": [
    "x_train_split, x_valid_split, y_train_split, y_valid_split = train_test_split(x_train\n",
    "                                                                              ,y_train\n",
    "                                                                              ,test_size=.1\n",
    "                                                                              ,random_state=42\n",
    "                                                                              ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lmMab-GG-B-"
   },
   "source": [
    "## Confirm Datasets {Train, Validation, Test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ma8OnyGRG-kW",
    "outputId": "cc00927c-7419-4974-91fc-da59c1914c8d"
   },
   "outputs": [],
   "source": [
    "print(x_train_split.shape, x_valid_split.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSSeL5MhhOBX"
   },
   "source": [
    "## Rescale Examples  {Train, Validation, Test}\n",
    "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2EQmIfNlxXQ"
   },
   "source": [
    "1. Each element in each example is a pixel value\n",
    "2. Pixel values range from 0 to 255\n",
    "3. 0 = black\n",
    "4. 255 = white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ab5d4b6"
   },
   "outputs": [],
   "source": [
    "x_train_norm = x_train_split/255\n",
    "x_valid_norm = x_valid_split/255\n",
    "x_test_norm = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Vc_MewNmIEj"
   },
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6oKF_JDmLEQ"
   },
   "source": [
    "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/CNN_architecture_v4.png?raw=1\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b1b4590"
   },
   "source": [
    "## Model and Performance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b7f8800"
   },
   "outputs": [],
   "source": [
    "def compile_train_model(model, x_train, y_train, x_valid, y_valid, epochs=200):\n",
    "  timestamp=int(time.time())\n",
    "  \n",
    "  # Compile\n",
    "  model.compile(optimizer='rmsprop',\n",
    "                loss = 'SparseCategoricalCrossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  # Train\n",
    "  start_time = time.time()\n",
    "  history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    #verbose=0,\n",
    "    callbacks=[    \n",
    "        EarlyStopping(monitor='val_accuracy', patience=3),\n",
    "        ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/models/model_{val_accuracy:.4f}.h5',\n",
    "                               save_best_only=True,\n",
    "                               save_weights_only=False,\n",
    "                               monitor='val_accuracy')]\n",
    "  )\n",
    "  end_time = time.time()\n",
    "  second_elapsed = round(end_time - start_time)\n",
    "\n",
    "  print(f'Finished model training in {second_elapsed}s')\n",
    "\n",
    "  print('Model performance with training set')\n",
    "  model.evaluate(x_train, y_train)\n",
    "\n",
    "  print('Evaluating model performance with validation set')\n",
    "  model.evaluate(x_valid, y_valid)\n",
    "\n",
    "  return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23cbe57e"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  losses = history.history['loss']\n",
    "  accs = history.history['accuracy']\n",
    "  val_losses = history.history['val_loss']\n",
    "  val_accs = history.history['val_accuracy']\n",
    "  epochs = len(losses)\n",
    "\n",
    "  plt.figure(figsize=(16, 4))\n",
    "  for i, metrics in enumerate(zip([losses, accs], [val_losses, val_accs], ['Loss', 'Accuracy'])):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[2]))\n",
    "    plt.plot(range(epochs), metrics[1], label='Validation {}'.format(metrics[2]))\n",
    "    plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ORQUqUuxcUq"
   },
   "outputs": [],
   "source": [
    "def print_validation_report(y_test, predictions):\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print('Accuracy Score: {}'.format(accuracy_score(y_test, predictions)))\n",
    "    print('Root Mean Square Error: {}'.format(np.sqrt(MSE(y_test, predictions)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAZahhJqxcee"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    mtx = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.75,  cbar=False, ax=ax,cmap='Blues',linecolor='white')\n",
    "    #  square=True,\n",
    "    plt.ylabel('true label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuYmec8fmW7Q"
   },
   "source": [
    "## Build CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BBOggAzmntF"
   },
   "source": [
    "We use a Sequential class defined in Keras to create our model. The first 9 layers Conv2D MaxPooling, Dropout handle feature learning.  The last 3 layers, handle classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3104070b",
    "outputId": "6eb0e6b6-d71c-4c83-a175-8348ccc42a9c"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu,input_shape=x_train_norm.shape[1:]),\n",
    "  MaxPool2D((2, 2),strides=2),\n",
    "  Dropout(0.3),\n",
    "  Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu),\n",
    "  MaxPool2D((2, 2),strides=2),\n",
    "  Dropout(0.3),\n",
    "  Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu),\n",
    "  MaxPool2D((2, 2),strides=2),\n",
    "  Dropout(0.3),\n",
    "  Flatten(),\n",
    "  Dense(units=384,activation=tf.nn.softmax,kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "  BatchNormalization(),\n",
    "  Dropout(0.3),\n",
    "  Dense(units=10, activation=tf.nn.softmax)       \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f25c9d57",
    "outputId": "803712a7-469e-4fa2-8915-fe8a2a6efcdf"
   },
   "outputs": [],
   "source": [
    "# Compile and train\n",
    "history, model = compile_train_model(model,\n",
    "                                     x_train_norm, y_train_split,\n",
    "                                     x_valid_norm, y_valid_split\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "86b2c00b",
    "outputId": "3d32019a-8418-423c-9c8a-cb6148fa54d5"
   },
   "outputs": [],
   "source": [
    "# Plot the training metrics\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GM9mVUU1pF0"
   },
   "source": [
    "## Confusion matrices\n",
    "Using both `sklearn.metrics`. Then we visualize the confusion matrix and see what that tells us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwvWBP9xxoQr"
   },
   "outputs": [],
   "source": [
    "pred1= model.predict(x_test_norm)\n",
    "pred1=np.argmax(pred1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0w9oMsNxofv",
    "outputId": "e3bb5307-78ad-4521-c688-a6cb137da6bf"
   },
   "outputs": [],
   "source": [
    "print_validation_report(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "4nA5VhUD0lD7",
    "outputId": "a0dd5355-ff08-4f1c-fe72-89d49eecd3dc"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a95a526f"
   },
   "outputs": [],
   "source": [
    "# Extracts the outputs of all layers:\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# Get activation values for the last dense layer\n",
    "activations = activation_model.predict(x_valid_norm[:5000])\n",
    "dense_layer_activations = activations[-3]\n",
    "output_layer_activations = activations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seh4myarrsWZ"
   },
   "source": [
    "## sklearn.manifold.TSNE\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dab01cd",
    "outputId": "81b3d715-ce15-4ca6-8713-29b66aa9b041"
   },
   "outputs": [],
   "source": [
    "# Reduce the dimension using T-SNE to visualize i n a scatterplot\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(dense_layer_activations)\n",
    "\n",
    "# Scaling\n",
    "tsne_results = (tsne_results - tsne_results.min()) / (tsne_results.max() - tsne_results.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "0999a430",
    "outputId": "b91b5b59-dca8-48ae-9f4c-a913346313f3"
   },
   "outputs": [],
   "source": [
    "\n",
    "cmap = plt.cm.tab10\n",
    "plt.figure(figsize=(16,10))\n",
    "scatter = plt.scatter(tsne_results[:,0],tsne_results[:,1], c=y_valid_split[:5000], s=10, cmap=cmap)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=class_names)\n",
    "\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(tsne_results):\n",
    "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
    "    if np.min(dist) > 0.02: # if far enough from other images\n",
    "        image_positions = np.r_[image_positions, [position]]\n",
    "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "            mpl.offsetbox.OffsetImage(x_train[index], cmap=\"binary\"),\n",
    "            position, bboxprops={\"lw\": 1})\n",
    "        plt.gca().add_artist(imagebox)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MSDS458_Assignment_02_ResearchExample_20210920_COLAB_Part2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
